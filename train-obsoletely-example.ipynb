{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.debugger import TensorBoardOutputConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"MobileNetV2\"\n",
    "EPOCHS = 3\n",
    "STEPS_PER_EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Upload local file or directory to S3.\n",
       "\n",
       "If a single file is specified for upload, the resulting S3 object key is\n",
       "``{key_prefix}/{filename}`` (filename does not include the local path, if any specified).\n",
       "\n",
       "If a directory is specified for upload, the API uploads all content, recursively,\n",
       "preserving relative structure of subdirectories. The resulting object key names are:\n",
       "``{key_prefix}/{relative_subdirectory_path}/filename``.\n",
       "\n",
       "Args:\n",
       "    path (str): Path (absolute or relative) of local file or directory to upload.\n",
       "    bucket (str): Name of the S3 Bucket to upload to (default: None). If not specified, the\n",
       "        default bucket of the ``Session`` is used (if default bucket does not exist, the\n",
       "        ``Session`` creates it).\n",
       "    key_prefix (str): Optional S3 object key name prefix (default: 'data'). S3 uses the\n",
       "        prefix to create a directory structure for the bucket content that it display in\n",
       "        the S3 console.\n",
       "    extra_args (dict): Optional extra arguments that may be passed to the upload operation.\n",
       "        Similar to ExtraArgs parameter in S3 upload_file function. Please refer to the\n",
       "        ExtraArgs parameter documentation here:\n",
       "        https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-uploading-files.html#the-extraargs-parameter\n",
       "\n",
       "Returns:\n",
       "    str: The S3 URI of the uploaded file(s). If a file is specified in the path argument,\n",
       "        the URI format is: ``s3://{bucket name}/{key_prefix}/{original_file_name}``.\n",
       "        If a directory is specified in the path argument, the URI format is\n",
       "        ``s3://{bucket name}/{key_prefix}``.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/sagemaker/session.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?sess.upload_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-475496805360/obsoletely_data/split_images\n"
     ]
    }
   ],
   "source": [
    "upload_data = True\n",
    "if upload_data:\n",
    "    data_input_path = sess.upload_data(\n",
    "        'obsoletely_data/split_images',\n",
    "        key_prefix='obsoletely_data/split_images'\n",
    "    )\n",
    "else:\n",
    "    data_input_path = \"s3://sagemaker-us-east-2-475496805360/obsoletely_data\"\n",
    "print(data_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_input_path = data_input_path + \"/train\"\n",
    "validation_input_path = data_input_path + \"/validate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = datetime.datetime.now().strftime(\"%Y-%m-%d_%Hh%Mm%Ss\")\n",
    "tensorboard_logs_dir = f\"s3://{sess.default_bucket()}/obsoletely_logs/{time_now}_{MODEL}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_output_config = TensorBoardOutputConfig(s3_output_path=tensorboard_logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator = TensorFlow(\n",
    "    entry_point='fine_tune_eff_net.py', \n",
    "    role=role,\n",
    "    instance_count=1, \n",
    "    instance_type='ml.g4dn.xlarge',  # local 'ml.g4dn.xlarge'\n",
    "    framework_version='2.3', \n",
    "    py_version='py37',\n",
    "    script_mode=True,\n",
    "    hyperparameters={\n",
    "        'epochs': EPOCHS,\n",
    "        \"steps-per-epoch\": STEPS_PER_EPOCH,\n",
    "        \"log-dir\": tensorboard_logs_dir,\n",
    "        \"model\": MODEL\n",
    "    },\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_estimator.fit(\n",
    "    {\n",
    "        'training': training_input_path, \n",
    "        'validation': validation_input_path, \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
